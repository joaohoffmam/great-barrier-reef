{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ed0fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T13:26:04.432564Z",
     "iopub.status.busy": "2022-02-21T13:26:04.431058Z",
     "iopub.status.idle": "2022-02-21T13:26:04.435665Z",
     "shell.execute_reply": "2022-02-21T13:26:04.435167Z",
     "shell.execute_reply.started": "2022-02-16T13:48:03.177401Z"
    },
    "papermill": {
     "duration": 0.020348,
     "end_time": "2022-02-21T13:26:04.435796",
     "exception": false,
     "start_time": "2022-02-21T13:26:04.415448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "continue_train_from_this_notebook = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eb2386",
   "metadata": {
    "papermill": {
     "duration": 0.004389,
     "end_time": "2022-02-21T13:26:04.445289",
     "exception": false,
     "start_time": "2022-02-21T13:26:04.440900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Copy files to output folder so training can go 100% offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4210405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T13:26:04.483101Z",
     "iopub.status.busy": "2022-02-21T13:26:04.482025Z",
     "iopub.status.idle": "2022-02-21T13:30:17.908911Z",
     "shell.execute_reply": "2022-02-21T13:30:17.907969Z",
     "shell.execute_reply.started": "2022-02-16T13:48:05.188531Z"
    },
    "papermill": {
     "duration": 253.459091,
     "end_time": "2022-02-21T13:30:17.909061",
     "exception": false,
     "start_time": "2022-02-21T13:26:04.449970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if continue_train_from_this_notebook:\n",
    "    # YOLOv5 source folder\n",
    "    !cp -r ../input/7-great-barrier-reef-train-the-bigger-yolov5/yolov5 ./yolov5\n",
    "    \n",
    "    # Training and validation datasets\n",
    "    !cp -r ../input/7-great-barrier-reef-train-the-bigger-yolov5/datasets ./datasets\n",
    "    \n",
    "    # Baseline weights\n",
    "    !cp ../input/7-great-barrier-reef-train-the-bigger-yolov5/yolov5/runs/train/exp4/weights/last.pt ./last.pt\n",
    "    \n",
    "    # Font required by the model\n",
    "    !cp ../input/7-great-barrier-reef-train-the-bigger-yolov5/Arial.ttf ./Arial.ttf\n",
    "    \n",
    "else:\n",
    "    # YOLOv5 source folder\n",
    "    !cp -r ../input/6-great-barrier-reef-start-a-bigger-yolov5/yolov5 ./yolov5\n",
    "    \n",
    "    # Training and validation datasets\n",
    "    !cp -r ../input/6-great-barrier-reef-start-a-bigger-yolov5/datasets ./datasets\n",
    "    \n",
    "    # Baseline weights\n",
    "    !cp ../input/6-great-barrier-reef-start-a-bigger-yolov5/yolov5/runs/train/exp/weights/last.pt ./last.pt\n",
    "    \n",
    "    # Font required by the model\n",
    "    !cp ../input/6-great-barrier-reef-start-a-bigger-yolov5/Arial.ttf ./Arial.ttf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1b56f",
   "metadata": {
    "papermill": {
     "duration": 0.004444,
     "end_time": "2022-02-21T13:30:17.919514",
     "exception": false,
     "start_time": "2022-02-21T13:30:17.915070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e97e3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T13:30:17.934199Z",
     "iopub.status.busy": "2022-02-21T13:30:17.933459Z",
     "iopub.status.idle": "2022-02-21T20:33:39.367039Z",
     "shell.execute_reply": "2022-02-21T20:33:39.366470Z",
     "shell.execute_reply.started": "2022-02-16T14:10:53.0146Z"
    },
    "papermill": {
     "duration": 25401.443234,
     "end_time": "2022-02-21T20:33:39.367224",
     "exception": false,
     "start_time": "2022-02-21T13:30:17.923990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m To use W&B in kaggle you must enable internet in the settings panel on the right.\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=last.pt, cfg=, data=GBR.yaml, hyp=yolov5/data/hyps/hyp.scratch.yaml, epochs=10, batch_size=16, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\r\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (offline), for updates see https://github.com/ultralytics/yolov5\r\n",
      "YOLOv5 ðŸš€ v6.0-255-gca0a007 torch 1.9.1 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\r\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1    885504  models.common.Conv                      [256, 384, 3, 2]              \r\n",
      "  8                -1  1    665856  models.common.C3                        [384, 384, 1]                 \r\n",
      "  9                -1  1   1770496  models.common.Conv                      [384, 512, 3, 2]              \r\n",
      " 10                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      " 11                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 12                -1  1    197376  models.common.Conv                      [512, 384, 1, 1]              \r\n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \r\n",
      " 15                -1  1    813312  models.common.C3                        [768, 384, 1, False]          \r\n",
      " 16                -1  1     98816  models.common.Conv                      [384, 256, 1, 1]              \r\n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 19                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 20                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 24                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \r\n",
      " 26                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 27                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \r\n",
      " 29                -1  1    715008  models.common.C3                        [512, 384, 1, False]          \r\n",
      " 30                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \r\n",
      " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \r\n",
      " 32                -1  1   1313792  models.common.C3                        [768, 512, 1, False]          \r\n",
      " 33  [23, 26, 29, 32]  1     23112  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [128, 256, 384, 512]]\r\n",
      "Model Summary: 355 layers, 12322312 parameters, 12322312 gradients\r\n",
      "\r\n",
      "Transferred 459/459 items from last.pt\r\n",
      "Scaled weight_decay = 0.0005\r\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 75 weight (no decay), 79 weight, 79 bias\r\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/kaggle/working/datasets/train.cache' images and labels... 2820\u001b[0m\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /kaggle/working/datasets/train/0-9470.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0021]\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/working/datasets/validation.cache' images and labels... 2\u001b[0m\r\n",
      "Plotting labels to yolov5/runs/train/exp5/labels.jpg... \r\n",
      "\r\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.88 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\r\n",
      "Image sizes 1280 train, 1280 val\r\n",
      "Using 2 dataloader workers\r\n",
      "Logging results to \u001b[1myolov5/runs/train/exp5\u001b[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       0/9     12.3G    0.0138  0.001689         0         2      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.681      0.292      0.378      0.191\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       1/9     12.8G   0.01351  0.001755         0         2      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.635      0.286      0.303      0.143\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       2/9     12.8G   0.01448  0.001823         0         9      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384       0.59      0.252      0.302      0.147\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       3/9     12.8G   0.01554  0.002027         0         2      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.507      0.251      0.283      0.137\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       4/9     12.8G   0.01557  0.002057         0         4      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.636      0.295      0.339      0.155\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       5/9     12.8G     0.015  0.002032         0         5      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.603      0.274      0.304      0.141\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       6/9     12.8G   0.01413  0.001885         0         4      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.551      0.285       0.33      0.165\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       7/9     12.8G   0.01359  0.001788         0         7      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.569       0.24      0.294      0.145\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       8/9     12.8G   0.01274  0.001749         0         3      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.561      0.266      0.312      0.155\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       9/9     12.8G   0.01255   0.00167         0         7      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.607      0.267      0.347      0.179\r\n",
      "\r\n",
      "10 epochs completed in 6.968 hours.\r\n",
      "Optimizer stripped from yolov5/runs/train/exp5/weights/last.pt, 25.4MB\r\n",
      "Optimizer stripped from yolov5/runs/train/exp5/weights/best.pt, 25.4MB\r\n",
      "\r\n",
      "Validating yolov5/runs/train/exp5/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "Model Summary: 280 layers, 12308200 parameters, 0 gradients\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.681      0.292      0.378      0.191\r\n",
      "Results saved to \u001b[1myolov5/runs/train/exp5\u001b[0m\r\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7300bd5050>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1262, in _shutdown_workers\r\n",
      "AttributeError: 'NoneType' object has no attribute 'python_exit_status'\r\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7300bd5050>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1262, in _shutdown_workers\r\n",
      "AttributeError: 'NoneType' object has no attribute 'python_exit_status'\r\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/train.py --img 1280 --batch 16 --epochs 10 --data GBR.yaml --weights last.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25667.518259,
   "end_time": "2022-02-21T20:33:44.115583",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-21T13:25:56.597324",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
