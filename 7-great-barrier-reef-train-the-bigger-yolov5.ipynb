{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8032e420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:19:22.041210Z",
     "iopub.status.busy": "2022-02-16T14:19:22.040460Z",
     "iopub.status.idle": "2022-02-16T14:19:22.047109Z",
     "shell.execute_reply": "2022-02-16T14:19:22.046034Z",
     "shell.execute_reply.started": "2022-02-16T13:48:03.177401Z"
    },
    "papermill": {
     "duration": 0.03055,
     "end_time": "2022-02-16T14:19:22.047300",
     "exception": false,
     "start_time": "2022-02-16T14:19:22.016750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "continue_train_from_this_notebook = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d72f82",
   "metadata": {
    "papermill": {
     "duration": 0.009406,
     "end_time": "2022-02-16T14:19:22.063908",
     "exception": false,
     "start_time": "2022-02-16T14:19:22.054502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Copy files to output folder so training can go 100% offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95c1e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:19:22.103139Z",
     "iopub.status.busy": "2022-02-16T14:19:22.102189Z",
     "iopub.status.idle": "2022-02-16T14:24:59.486053Z",
     "shell.execute_reply": "2022-02-16T14:24:59.484416Z",
     "shell.execute_reply.started": "2022-02-16T13:48:05.188531Z"
    },
    "papermill": {
     "duration": 337.414498,
     "end_time": "2022-02-16T14:24:59.486264",
     "exception": false,
     "start_time": "2022-02-16T14:19:22.071766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if continue_train_from_this_notebook:\n",
    "    # YOLOv5 source folder\n",
    "    !cp -r ../input/7-great-barrier-reef-train-the-bigger-yolov5/yolov5 ./yolov5\n",
    "    \n",
    "    # Training and validation datasets\n",
    "    !cp -r ../input/7-great-barrier-reef-train-the-bigger-yolov5/datasets ./datasets\n",
    "    \n",
    "    # Baseline weights\n",
    "    !cp ../input/7-great-barrier-reef-train-the-bigger-yolov5/yolov5/runs/train/exp2/weights/last.pt ./last.pt\n",
    "    \n",
    "    # Font required by the model\n",
    "    !cp ../input/7-great-barrier-reef-train-the-bigger-yolov5/Arial.ttf ./Arial.ttf\n",
    "    \n",
    "else:\n",
    "    # YOLOv5 source folder\n",
    "    !cp -r ../input/6-great-barrier-reef-start-a-bigger-yolov5/yolov5 ./yolov5\n",
    "    \n",
    "    # Training and validation datasets\n",
    "    !cp -r ../input/6-great-barrier-reef-start-a-bigger-yolov5/datasets ./datasets\n",
    "    \n",
    "    # Baseline weights\n",
    "    !cp ../input/6-great-barrier-reef-start-a-bigger-yolov5/yolov5/runs/train/exp/weights/last.pt ./last.pt\n",
    "    \n",
    "    # Font required by the model\n",
    "    !cp ../input/6-great-barrier-reef-start-a-bigger-yolov5/Arial.ttf ./Arial.ttf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd726e",
   "metadata": {
    "papermill": {
     "duration": 0.011914,
     "end_time": "2022-02-16T14:24:59.509145",
     "exception": false,
     "start_time": "2022-02-16T14:24:59.497231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3fe7ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-16T14:24:59.537681Z",
     "iopub.status.busy": "2022-02-16T14:24:59.536746Z",
     "iopub.status.idle": "2022-02-16T21:15:26.874836Z",
     "shell.execute_reply": "2022-02-16T21:15:26.874250Z",
     "shell.execute_reply.started": "2022-02-16T14:10:53.014600Z"
    },
    "papermill": {
     "duration": 24627.357714,
     "end_time": "2022-02-16T21:15:26.874990",
     "exception": false,
     "start_time": "2022-02-16T14:24:59.517276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m To use W&B in kaggle you must enable internet in the settings panel on the right.\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=last.pt, cfg=, data=GBR.yaml, hyp=yolov5/data/hyps/hyp.scratch.yaml, epochs=10, batch_size=16, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\r\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (offline), for updates see https://github.com/ultralytics/yolov5\r\n",
      "YOLOv5 ðŸš€ v6.0-255-gca0a007 torch 1.9.1 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\r\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \r\n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \r\n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \r\n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \r\n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \r\n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \r\n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \r\n",
      "  7                -1  1    885504  models.common.Conv                      [256, 384, 3, 2]              \r\n",
      "  8                -1  1    665856  models.common.C3                        [384, 384, 1]                 \r\n",
      "  9                -1  1   1770496  models.common.Conv                      [384, 512, 3, 2]              \r\n",
      " 10                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \r\n",
      " 11                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \r\n",
      " 12                -1  1    197376  models.common.Conv                      [512, 384, 1, 1]              \r\n",
      " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \r\n",
      " 15                -1  1    813312  models.common.C3                        [768, 384, 1, False]          \r\n",
      " 16                -1  1     98816  models.common.Conv                      [384, 256, 1, 1]              \r\n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 19                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \r\n",
      " 20                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \r\n",
      " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \r\n",
      " 24                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \r\n",
      " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \r\n",
      " 26                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \r\n",
      " 27                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \r\n",
      " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \r\n",
      " 29                -1  1    715008  models.common.C3                        [512, 384, 1, False]          \r\n",
      " 30                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \r\n",
      " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \r\n",
      " 32                -1  1   1313792  models.common.C3                        [768, 512, 1, False]          \r\n",
      " 33  [23, 26, 29, 32]  1     23112  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [128, 256, 384, 512]]\r\n",
      "Model Summary: 355 layers, 12322312 parameters, 12322312 gradients\r\n",
      "\r\n",
      "Transferred 459/459 items from last.pt\r\n",
      "Scaled weight_decay = 0.0005\r\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 75 weight (no decay), 79 weight, 79 bias\r\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/kaggle/working/datasets/train.cache' images and labels... 2820\u001b[0m\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /kaggle/working/datasets/train/0-9470.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0021]\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/kaggle/working/datasets/validation.cache' images and labels... 2\u001b[0m\r\n",
      "Plotting labels to yolov5/runs/train/exp3/labels.jpg... \r\n",
      "\r\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.88 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\r\n",
      "Image sizes 1280 train, 1280 val\r\n",
      "Using 2 dataloader workers\r\n",
      "Logging results to \u001b[1myolov5/runs/train/exp3\u001b[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       0/9     13.3G     0.016  0.002072         0         2      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.655      0.315      0.373      0.181\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       1/9     13.3G   0.01652  0.002181         0         2      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.638      0.302      0.347      0.161\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       2/9     13.3G   0.01798  0.002356         0         9      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.532      0.247      0.263      0.118\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       3/9     13.3G   0.01906  0.002641         0         2      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.602      0.278      0.307      0.141\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       4/9     13.3G   0.01852  0.002585         0         4      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.602      0.295      0.334      0.152\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       5/9     13.3G   0.01736  0.002412         0         5      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.575      0.277      0.302      0.139\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       6/9     13.3G   0.01641  0.002204         0         4      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.549      0.282      0.313      0.152\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       7/9     13.3G   0.01557  0.002061         0         7      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.506      0.247      0.274      0.129\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       8/9     13.3G   0.01451  0.001954         0         3      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.594      0.291      0.339      0.164\r\n",
      "\r\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\r\n",
      "       9/9     13.3G   0.01415  0.001868         0         7      1280: 100%|â–ˆâ–ˆâ–ˆ\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.621      0.302      0.367      0.182\r\n",
      "\r\n",
      "10 epochs completed in 6.752 hours.\r\n",
      "Optimizer stripped from yolov5/runs/train/exp3/weights/last.pt, 25.4MB\r\n",
      "Optimizer stripped from yolov5/runs/train/exp3/weights/best.pt, 25.4MB\r\n",
      "\r\n",
      "Validating yolov5/runs/train/exp3/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "Model Summary: 280 layers, 12308200 parameters, 0 gradients\r\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\r\n",
      "                 all       8232       6384      0.667      0.312      0.373      0.181\r\n",
      "Results saved to \u001b[1myolov5/runs/train/exp3\u001b[0m\r\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda856d3050>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1262, in _shutdown_workers\r\n",
      "AttributeError: 'NoneType' object has no attribute 'python_exit_status'\r\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fda856d3050>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1262, in _shutdown_workers\r\n",
      "AttributeError: 'NoneType' object has no attribute 'python_exit_status'\r\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/train.py --img 1280 --batch 16 --epochs 10 --data GBR.yaml --weights last.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24977.531191,
   "end_time": "2022-02-16T21:15:31.540097",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-16T14:19:14.008906",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
