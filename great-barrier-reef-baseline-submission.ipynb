{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport greatbarrierreef","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-09T02:57:36.252470Z","iopub.execute_input":"2022-02-09T02:57:36.253382Z","iopub.status.idle":"2022-02-09T02:57:37.494388Z","shell.execute_reply.started":"2022-02-09T02:57:36.253221Z","shell.execute_reply":"2022-02-09T02:57:37.493531Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!cp ../input/great-barrier-reef-making-baseline-predictions/Arial.ttf ./Arial.ttf","metadata":{"execution":{"iopub.status.busy":"2022-02-09T02:58:01.123484Z","iopub.execute_input":"2022-02-09T02:58:01.123793Z","iopub.status.idle":"2022-02-09T02:58:01.859071Z","shell.execute_reply.started":"2022-02-09T02:58:01.123762Z","shell.execute_reply":"2022-02-09T02:58:01.858106Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Loading the baseline model\nmodel_path = '../input/great-barrier-reef-making-baseline-predictions/yolov5'\nweights_path = '../input/great-barrier-reef-making-baseline-predictions/baseline.pt'\n\nmodel = torch.hub.load(model_path, 'custom', path = weights_path, source = 'local')","metadata":{"execution":{"iopub.status.busy":"2022-02-09T02:58:04.463978Z","iopub.execute_input":"2022-02-09T02:58:04.464299Z","iopub.status.idle":"2022-02-09T02:58:06.942939Z","shell.execute_reply.started":"2022-02-09T02:58:04.464265Z","shell.execute_reply":"2022-02-09T02:58:06.942123Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"YOLOv5 ðŸš€ v6.0-216-g856d4e5 torch 1.9.1+cpu CPU\n\nFusing layers... \nModel Summary: 213 layers, 1760518 parameters, 0 gradients\nAdding AutoShape... \n","output_type":"stream"}]},{"cell_type":"code","source":"env = greatbarrierreef.make_env()\niter_test = env.iter_test()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (pixel_array, sample_prediction_df) in iter_test:\n    results = model(pixel_array)\n    annotation = ''\n    \n    for index, row in results.pandas().xyxy[0].iterrows():\n        annotation += ' ' + str(row['confidence']) + ' ' + str(row['xmin']) + ' ' + str(row['ymin'])\n        annotation += ' ' + str(row['xmax'] - row['xmin']) + ' ' + str(row['ymax'] - row['ymin'])\n    \n    sample_prediction_df['annotations'] = annotation.strip()\n    env.predict(sample_prediction_df)","metadata":{},"execution_count":null,"outputs":[]}]}